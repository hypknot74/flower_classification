{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm\n",
    "# !pip install wandb\n",
    "# wandb login <wandb API>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1632393760783,
     "user": {
      "displayName": "畠山太郎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11861445867020192056"
     },
     "user_tz": -540
    },
    "id": "BZ4Lcz4-2qde"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    wandb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1632393760784,
     "user": {
      "displayName": "畠山太郎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11861445867020192056"
     },
     "user_tz": -540
    },
    "id": "myjw-lhJg05P",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a5caa53f-8002-47c3-d17f-c4e99c96a9fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'fbnetc_100',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_s16_224',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mnasnet_100',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_resnet50',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet101d',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_100',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext50_32x4d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 対応モデルを確認\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1632393760785,
     "user": {
      "displayName": "畠山太郎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11861445867020192056"
     },
     "user_tz": -540
    },
    "id": "s5cb6040iM9s",
    "outputId": "3a004e04-47bb-4e36-b423-dd4ed6abf9f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base config\n",
    "DATASET_PATH = './jpeg-512x512/'\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "NUM_FINETUNE_CLASSES = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1632393761708,
     "user": {
      "displayName": "畠山太郎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11861445867020192056"
     },
     "user_tz": -540
    },
    "id": "-aseDUzb3VFJ"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATASET_PATH, x),data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=BATCH_SIZE,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='tf_efficientnet_b5_ns',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0,\n",
    "                 s=30.0,\n",
    "                 margin=0.50,\n",
    "                 ls_eps=0.0,\n",
    "                 theta_zero=0.785,\n",
    "                 pretrained=True,\n",
    "                 classification_checkpoint=None):\n",
    "        \n",
    "        super(FlowerModel, self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=n_classes)\n",
    "        \n",
    "        if classification_checkpoint:\n",
    "            ckpt = torch.load(classification_checkpoint)\n",
    "            self.backbone.load_state_dict(ckpt['weight'])\n",
    "            print('loaded checkpoint weights!')            \n",
    "            \n",
    "        final_in_features = self.backbone.classifier.in_features\n",
    "        \n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "            \n",
    "        self.use_fc = use_fc\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        self.final = nn.Linear(final_in_features, n_classes)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.extract_feat(x)\n",
    "        logits = self.final(feature)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1632393761708,
     "user": {
      "displayName": "畠山太郎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11861445867020192056"
     },
     "user_tz": -540
    },
    "id": "Hd2vfPF_71H5"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10, start_epoch=0):\n",
    "    # wandb\n",
    "    if wandb is not None and WANDB:\n",
    "        wandb.init(\n",
    "            project=\"Flower_Classification\",\n",
    "            config={\n",
    "                'start_epoch' : START_EPOCH,\n",
    "                'epochs' : EPOCHS,\n",
    "                'batch_size' : BATCH_SIZE,\n",
    "                'model' : MODEL_NAME,\n",
    "                'checkpoint' : CKPT,\n",
    "                'lr' : LR,\n",
    "                'step_size' : STEP_SIZE,\n",
    "                'dataset' : DATASET_PATH\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # エポック\n",
    "    for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # train, value\n",
    "        for phase in ['train', 'val']:\n",
    "            print(f'Phase: {phase}')\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # バッチずつ\n",
    "            with tqdm(dataloaders[phase]) as pbar:\n",
    "                for i, (inputs, labels) in enumerate(pbar):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0) # バッチ数でかける\n",
    "                    running_corrects += torch.sum(preds == labels.data).item()\n",
    "                    pbar.set_postfix(OrderedDict(loss=loss.item(), acc=torch.sum(preds == labels.data).item()/4))\n",
    "                    \n",
    "                    # wandb\n",
    "                    if phase == 'train' and wandb and WANDB:\n",
    "                        wandb.log(\n",
    "                            {\n",
    "                                \"loss/train\": loss.item(),\n",
    "                                \"acc/train\": torch.sum(preds == labels.data).item()/4,\n",
    "                            }\n",
    "                        )\n",
    "                    elif phase == 'val' and wandb and WANDB:\n",
    "                        wandb.log(\n",
    "                            {\n",
    "                                \"loss/val\": loss.item(),\n",
    "                                \"acc/val\": torch.sum(preds == labels.data).item()/4,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # wandb\n",
    "            if phase == 'train' and wandb and WANDB:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch_loss/train\": epoch_loss,\n",
    "                        \"epoch_acc/train\": epoch_acc,\n",
    "                    }\n",
    "                )\n",
    "            elif phase == 'val' and wandb and WANDB:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch_loss/val\": epoch_loss,\n",
    "                        \"epoch_acc/val\": epoch_acc,\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save({'weight':model.state_dict(),\n",
    "                           'optimizer':optimizer.state_dict(),\n",
    "                           'scheduler':scheduler.state_dict()},\n",
    "                           os.path.join(OUTPUT_PATH, f\"{MODEL_NAME}_best.pth\"))\n",
    "                best_epoch = epoch+1\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "    print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    if wandb is not None and WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2467,
     "status": "ok",
     "timestamp": 1632393764172,
     "user": {
      "displayName": "畠山太郎",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11861445867020192056"
     },
     "user_tz": -540
    },
    "id": "6w-191-avkVr",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-resonance-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hypknot/Flower_Classification\" target=\"_blank\">https://wandb.ai/hypknot/Flower_Classification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hypknot/Flower_Classification/runs/2oz3xz7p\" target=\"_blank\">https://wandb.ai/hypknot/Flower_Classification/runs/2oz3xz7p</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/flower_classification/wandb/run-20210923_154811-2oz3xz7p</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 2108/3189 [07:50<04:02,  4.45it/s, loss=0.511, acc=1]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3189/3189 [11:51<00:00,  4.48it/s, loss=3.46, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.6580 Acc: 0.6215\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:53<00:00,  4.47it/s, loss=4.93, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5440 Acc: 0.8723\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 407/928 [00:32<00:41, 12.65it/s, loss=0.00693, acc=1] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 93%|█████████▎| 2970/3189 [11:03<00:49,  4.46it/s, loss=0.00187, acc=1] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3189/3189 [11:50<00:00,  4.49it/s, loss=3.98, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2080 Acc: 0.9523\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:14<00:00, 12.39it/s, loss=0.414, acc=0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2272 Acc: 0.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 238/3189 [00:53<10:59,  4.47it/s, loss=0.0238, acc=1]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 90%|████████▉ | 2866/3189 [10:41<01:12,  4.47it/s, loss=0.0166, acc=1]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 928/928 [01:13<00:00, 12.56it/s, loss=0.00174, acc=1] \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2314 Acc: 0.9472\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1915/3189 [07:08<04:45,  4.46it/s, loss=0.0126, acc=1]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3189/3189 [11:52<00:00,  4.47it/s, loss=2.29, acc=0.25] \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0885 Acc: 0.9809\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:15<00:00, 12.33it/s, loss=0.000795, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2161 Acc: 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1674/3189 [06:14<05:37,  4.49it/s, loss=0.0192, acc=1]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3189/3189 [11:52<00:00,  4.48it/s, loss=1.84, acc=0.25] \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0718 Acc: 0.9858\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:14<00:00, 12.39it/s, loss=0.194, acc=0.75]\n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2205 Acc: 0.9504\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 745/3189 [02:47<09:02,  4.50it/s, loss=0.00482, acc=1] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 3189/3189 [11:51<00:00,  4.48it/s, loss=3.79, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0750 Acc: 0.9847\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 622/928 [00:50<00:24, 12.57it/s, loss=0.00574, acc=1] "
     ]
    }
   ],
   "source": [
    "START_EPOCH = 0\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "NUM_FINETUNE_CLASSES = 104\n",
    "\n",
    "LR = 0.001\n",
    "STEP_SIZE = 5\n",
    "\n",
    "WANDB = True\n",
    "\n",
    "MODEL_NAME = 'tf_efficientnet_b5_ns'\n",
    "CKPT = None\n",
    "\n",
    "OUTPUT_PATH = f'./output/{MODEL_NAME}/'\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=STEP_SIZE, gamma=0.1)\n",
    "\n",
    "model.to(device)   \n",
    "\n",
    "if CKPT:\n",
    "    ckpt = torch.load(CKPT)\n",
    "    model.load_state_dict(ckpt['weight'])\n",
    "    optimizer_ft.load_state_dict(ckpt['optimizer'])\n",
    "    exp_lr_scheduler.load_state_dict(ckpt['scheduler'])\n",
    "    print('loaded checkpoint!')\n",
    "    \n",
    "train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCHS, start_epoch=START_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">astral-water-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hypknot/Flower_Classification\" target=\"_blank\">https://wandb.ai/hypknot/Flower_Classification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hypknot/Flower_Classification/runs/mxpj8ydg\" target=\"_blank\">https://wandb.ai/hypknot/Flower_Classification/runs/mxpj8ydg</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/flower_classification/wandb/run-20210924_011432-mxpj8ydg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [12:00<00:00,  4.43it/s, loss=2.47, acc=0.25] \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0624 Acc: 0.9881\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:15<00:00, 12.27it/s, loss=3.98e-5, acc=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2166 Acc: 0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:53<00:00,  4.47it/s, loss=4.21, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0575 Acc: 0.9897\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:15<00:00, 12.30it/s, loss=9.01e-5, acc=1] \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2135 Acc: 0.9523\n",
      "\n",
      "Epoch 13/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:52<00:00,  4.48it/s, loss=5.23, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0571 Acc: 0.9902\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:13<00:00, 12.59it/s, loss=0.000151, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2103 Acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:48<00:00,  4.50it/s, loss=4.88, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0608 Acc: 0.9887\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:13<00:00, 12.56it/s, loss=0.215, acc=0.75]\n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2002 Acc: 0.9539\n",
      "\n",
      "Epoch 15/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:57<00:00,  4.45it/s, loss=4.82, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0541 Acc: 0.9907\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:16<00:00, 12.12it/s, loss=0.0383, acc=1]  \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2078 Acc: 0.9534\n",
      "\n",
      "Epoch 16/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:56<00:00,  4.45it/s, loss=2.22, acc=0.25] \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0522 Acc: 0.9911\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:15<00:00, 12.35it/s, loss=0.0176, acc=1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2037 Acc: 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:56<00:00,  4.45it/s, loss=4.61, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0587 Acc: 0.9906\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:16<00:00, 12.16it/s, loss=0.487, acc=0.75]\n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2003 Acc: 0.9553\n",
      "\n",
      "Epoch 18/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:54<00:00,  4.46it/s, loss=3.46, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0558 Acc: 0.9899\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:15<00:00, 12.31it/s, loss=0.00301, acc=1] \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2219 Acc: 0.9553\n",
      "\n",
      "Epoch 19/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:56<00:00,  4.45it/s, loss=4.77, acc=0]    \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0576 Acc: 0.9900\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:16<00:00, 12.16it/s, loss=0.0519, acc=1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2007 Acc: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/10\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [11:57<00:00,  4.45it/s, loss=3.1, acc=0]     \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0572 Acc: 0.9904\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/928 [00:01<01:19, 11.55it/s, loss=0.00447, acc=1] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "START_EPOCH = 10\n",
    "EPOCHS = 10\n",
    "\n",
    "LR = 0.001\n",
    "STEP_SIZE = 5\n",
    "\n",
    "WANDB = True\n",
    "\n",
    "MODEL_NAME = 'tf_efficientnet_b5_ns'\n",
    "CKPT = './output/tf_efficientnet_b5_ns/tf_efficientnet_b5_ns_best.pth'\n",
    "\n",
    "OUTPUT_PATH = f'./output/{MODEL_NAME}/'\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=STEP_SIZE, gamma=0.1)\n",
    "\n",
    "model.to(device)   \n",
    "\n",
    "if CKPT:\n",
    "    ckpt = torch.load(CKPT)\n",
    "    model.load_state_dict(ckpt['weight'])\n",
    "    optimizer_ft.load_state_dict(ckpt['optimizer'])\n",
    "    exp_lr_scheduler.load_state_dict(ckpt['scheduler'])\n",
    "    print('loaded checkpoint!')\n",
    "    \n",
    "train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=EPOCHS, start_epoch=START_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 距離学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from pytorch_metric_learning.losses import TripletMarginLoss\n",
    "from pytorch_metric_learning.reducers import ThresholdReducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_metric_model(model, losser, mininer, optimizer, scheduler, num_epochs=10, start_epoch=0):\n",
    "    # wandb\n",
    "    if wandb is not None and WANDB:\n",
    "        wandb.init(\n",
    "            project=\"Flower_Classification\",\n",
    "            config={\n",
    "                'start_epoch' : START_EPOCH,\n",
    "                'epochs' : EPOCHS,\n",
    "                'batch_size' : BATCH_SIZE,\n",
    "                'model' : MODEL_NAME,\n",
    "                'checkpoint' : CKPT,\n",
    "                'lr' : LR,\n",
    "                'step_size' : STEP_SIZE,\n",
    "                'dataset' : DATASET_PATH\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    best_loss = 0.0\n",
    "    \n",
    "    # エポック\n",
    "    for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # train, value\n",
    "        for phase in ['train', 'val']:\n",
    "            print(f'Phase: {phase}')\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # バッチずつ\n",
    "            with tqdm(dataloaders[phase]) as pbar:\n",
    "                for i, (inputs, labels) in enumerate(pbar):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        embeddings = model(inputs)\n",
    "                        indices_tuple = mininer(embeddings, labels)\n",
    "                        loss = losser(embeddings, labels, indices_tuple)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0) # バッチ数でかける\n",
    "                    pbar.set_postfix(OrderedDict(loss=loss.item(), n_mined_triplets=mininer.num_triplets))\n",
    "                    \n",
    "                    # wandb\n",
    "                    if phase == 'train' and wandb and WANDB:\n",
    "                        wandb.log(\n",
    "                            {\n",
    "                                \"loss/train\": loss,\n",
    "                            }\n",
    "                        )\n",
    "                    elif phase == 'val' and wandb and WANDB:\n",
    "                        wandb.log(\n",
    "                            {\n",
    "                                \"loss/val\": loss,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            # wandb\n",
    "            if phase == 'train' and wandb and WANDB:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch_loss/train\": epoch_loss,\n",
    "                    }\n",
    "                )\n",
    "            elif phase == 'val' and wandb and WANDB:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"epoch_loss/val\": epoch_loss,\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            if phase == 'val' and epoch_loss > best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save({'weight':model.state_dict(),\n",
    "                           'optimizer':optimizer.state_dict(),\n",
    "                           'scheduler':scheduler.state_dict()},\n",
    "                           os.path.join(OUTPUT_PATH, f\"{MODEL_NAME}_best.pth\"))\n",
    "                best_epoch = epoch+1\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Loss: {best_loss:4f}')\n",
    "    print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    if wandb is not None and WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for tf_efficientnet_b5_ns model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint weights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhypknot\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">stilted-bee-13</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/hypknot/Flower_Classification\" target=\"_blank\">https://wandb.ai/hypknot/Flower_Classification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/hypknot/Flower_Classification/runs/5m0gf4op\" target=\"_blank\">https://wandb.ai/hypknot/Flower_Classification/runs/5m0gf4op</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/flower_classification/wandb/run-20210925_002742-5m0gf4op</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:36<00:00,  3.91it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0288\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.56it/s, loss=0, n_mined_triplets=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:36<00:00,  3.91it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0247\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:19<00:00, 11.66it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0217\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:38<00:00,  3.90it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0217\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:19<00:00, 11.64it/s, loss=0.181, n_mined_triplets=2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:35<00:00,  3.91it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0211\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:17<00:00, 11.96it/s, loss=0, n_mined_triplets=0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:37<00:00,  3.90it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0230\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.56it/s, loss=0, n_mined_triplets=0]     \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0235\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:37<00:00,  3.90it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0225\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.51it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0188\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:38<00:00,  3.89it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0230\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.52it/s, loss=0, n_mined_triplets=0]     \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0205\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:43<00:00,  3.87it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0218\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:19<00:00, 11.66it/s, loss=0, n_mined_triplets=0]     \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0240\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:39<00:00,  3.89it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0191\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.57it/s, loss=0.301, n_mined_triplets=2]  \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0189\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:41<00:00,  3.88it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0211\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:18<00:00, 11.84it/s, loss=0, n_mined_triplets=0]     \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0189\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:41<00:00,  3.88it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0202\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:19<00:00, 11.64it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0186\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:42<00:00,  3.88it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0185\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.58it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0244\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:38<00:00,  3.90it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0165\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.56it/s, loss=0, n_mined_triplets=0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:33<00:00,  3.92it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0184\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:18<00:00, 11.76it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0157\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:41<00:00,  3.88it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0186\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.48it/s, loss=0.0625, n_mined_triplets=2]\n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0206\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:39<00:00,  3.89it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0196\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:18<00:00, 11.76it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0208\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:38<00:00,  3.89it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0159\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:18<00:00, 11.82it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0195\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:39<00:00,  3.89it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0183\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.56it/s, loss=0, n_mined_triplets=0]     \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0215\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:39<00:00,  3.89it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0171\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:18<00:00, 11.81it/s, loss=0, n_mined_triplets=0]      \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0204\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [13:37<00:00,  3.90it/s, loss=0, n_mined_triplets=0]       \n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0161\n",
      "Phase: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [01:20<00:00, 11.49it/s, loss=0, n_mined_triplets=0]     \n",
      "  0%|          | 0/3189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0215\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "Phase: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 491/3189 [02:06<11:27,  3.92it/s, loss=0, n_mined_triplets=0]       "
     ]
    }
   ],
   "source": [
    "START_EPOCH = 0\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "NUM_FINETUNE_CLASSES = 104\n",
    "\n",
    "LR = 1e-4\n",
    "STEP_SIZE = 5\n",
    "\n",
    "WANDB = True\n",
    "\n",
    "MODEL_NAME = 'tf_efficientnet_b5_ns'\n",
    "CKPT = './output/tf_efficientnet_b5_ns/tf_efficientnet_b5_ns_best.pth'\n",
    "\n",
    "model_params = {\n",
    "    'n_classes':104,\n",
    "    'model_name':MODEL_NAME,\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.0,\n",
    "    's':30.0,\n",
    "    'margin':0.50,\n",
    "    'ls_eps':0.0,\n",
    "    'theta_zero':0.785,\n",
    "    'pretrained':False,\n",
    "    'classification_checkpoint':CKPT\n",
    "}\n",
    "\n",
    "OUTPUT_PATH = f'./output/metric/{MODEL_NAME}/'\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "model = FlowerModel(**model_params)\n",
    "\n",
    "distance = CosineSimilarity()\n",
    "reducer = ThresholdReducer(low = 0)\n",
    "losser = TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "miner = TripletMarginMiner(margin=0.2, distance=distance)\n",
    "\n",
    "metric_optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "metric_lr_scheduler = lr_scheduler.StepLR(metric_optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "model.to(device)   \n",
    "    \n",
    "train_metric_model(model, losser, miner, metric_optimizer, metric_lr_scheduler, num_epochs=EPOCHS, start_epoch=START_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlowerModel(\n",
       "  (backbone): EfficientNet(\n",
       "    (conv_stem): Conv2dSame(3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): SiLU(inplace=True)\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "          (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "        (1): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "        (2): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "          (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(240, 240, kernel_size=(5, 5), stride=(2, 2), groups=240, bias=False)\n",
       "          (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
       "          (bn2): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
       "          (bn2): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(176, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2dSame(1056, 1056, kernel_size=(5, 5), stride=(2, 2), groups=1056, bias=False)\n",
       "          (bn2): BatchNorm2d(1056, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
       "          (bn2): BatchNorm2d(1824, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "          (bn2): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "          (bn2): BatchNorm2d(3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): SiLU(inplace=True)\n",
       "    (global_pool): Identity()\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (final): Linear(in_features=2048, out_features=104, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(model, dataloader):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_loss = 0.0\n",
    "    \n",
    "    model.eval()   \n",
    "\n",
    "    _predicted_metrics = []\n",
    "    _true_labels = []\n",
    "\n",
    "    # バッチずつ\n",
    "    for i, (inputs, labels) in tqdm(enumerate(dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            metric = model(inputs).detach().cpu().numpy()\n",
    "            metric = metric.reshape(metric.shape[0], metric.shape[1])\n",
    "            _predicted_metrics.append(metric)\n",
    "            _true_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    \n",
    "    return np.concatenate(_predicted_metrics), np.concatenate(_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for tf_efficientnet_b5_ns model\n",
      "loaded checkpoint weights!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "928it [00:53, 17.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 0m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'tf_efficientnet_b5_ns'\n",
    "CKPT = './output/metric/tf_efficientnet_b5_ns/tf_efficientnet_b5_ns_best.pth'\n",
    "\n",
    "model_params = {\n",
    "    'n_classes':104,\n",
    "    'model_name':MODEL_NAME,\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.0,\n",
    "    's':30.0,\n",
    "    'margin':0.50,\n",
    "    'ls_eps':0.0,\n",
    "    'theta_zero':0.785,\n",
    "    'pretrained':False\n",
    "}\n",
    "\n",
    "OUTPUT_PATH = f'./output/metric/{MODEL_NAME}/'\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "model = FlowerModel(**model_params)\n",
    "     \n",
    "ckpt = torch.load(CKPT)\n",
    "model.load_state_dict(ckpt['weight'])\n",
    "print('loaded checkpoint weights!')   \n",
    "\n",
    "model.to(device)   \n",
    "    \n",
    "predicted_metrics, labels = feature_extraction(model, dataloaders['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dfに出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [class_names_val[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predicted_metrics, columns=[f'feat_{i}' for i in range(len(predicted_metrics[0]))])\n",
    "df['label'] = label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_95</th>\n",
       "      <th>feat_96</th>\n",
       "      <th>feat_97</th>\n",
       "      <th>feat_98</th>\n",
       "      <th>feat_99</th>\n",
       "      <th>feat_100</th>\n",
       "      <th>feat_101</th>\n",
       "      <th>feat_102</th>\n",
       "      <th>feat_103</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.800802</td>\n",
       "      <td>-6.686755</td>\n",
       "      <td>2.291890</td>\n",
       "      <td>-6.562728</td>\n",
       "      <td>7.745037</td>\n",
       "      <td>6.728537</td>\n",
       "      <td>-2.491809</td>\n",
       "      <td>-4.484881</td>\n",
       "      <td>-2.737143</td>\n",
       "      <td>7.932643</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.565012</td>\n",
       "      <td>5.332066</td>\n",
       "      <td>0.745956</td>\n",
       "      <td>2.969701</td>\n",
       "      <td>2.638199</td>\n",
       "      <td>7.016939</td>\n",
       "      <td>7.624356</td>\n",
       "      <td>2.285954</td>\n",
       "      <td>-4.529178</td>\n",
       "      <td>foxglove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.062384</td>\n",
       "      <td>-9.090408</td>\n",
       "      <td>2.106473</td>\n",
       "      <td>-8.307278</td>\n",
       "      <td>10.665771</td>\n",
       "      <td>9.068426</td>\n",
       "      <td>-3.133069</td>\n",
       "      <td>-5.898288</td>\n",
       "      <td>-2.975612</td>\n",
       "      <td>10.400145</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.275208</td>\n",
       "      <td>7.315140</td>\n",
       "      <td>0.826239</td>\n",
       "      <td>4.833378</td>\n",
       "      <td>2.779420</td>\n",
       "      <td>9.377540</td>\n",
       "      <td>10.458584</td>\n",
       "      <td>2.551416</td>\n",
       "      <td>-6.206422</td>\n",
       "      <td>passion flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.133140</td>\n",
       "      <td>-5.564013</td>\n",
       "      <td>7.093954</td>\n",
       "      <td>-6.700411</td>\n",
       "      <td>5.081787</td>\n",
       "      <td>4.433008</td>\n",
       "      <td>-3.458238</td>\n",
       "      <td>-2.864730</td>\n",
       "      <td>-3.854272</td>\n",
       "      <td>7.458284</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.598590</td>\n",
       "      <td>2.709342</td>\n",
       "      <td>1.422618</td>\n",
       "      <td>0.412841</td>\n",
       "      <td>4.528669</td>\n",
       "      <td>3.052601</td>\n",
       "      <td>4.200697</td>\n",
       "      <td>3.536117</td>\n",
       "      <td>-2.623990</td>\n",
       "      <td>common tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.015239</td>\n",
       "      <td>-8.601444</td>\n",
       "      <td>2.186274</td>\n",
       "      <td>-7.964367</td>\n",
       "      <td>10.071804</td>\n",
       "      <td>8.585188</td>\n",
       "      <td>-2.997392</td>\n",
       "      <td>-5.624932</td>\n",
       "      <td>-2.950619</td>\n",
       "      <td>9.911002</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.716297</td>\n",
       "      <td>6.910458</td>\n",
       "      <td>0.792586</td>\n",
       "      <td>4.439338</td>\n",
       "      <td>2.776150</td>\n",
       "      <td>8.899710</td>\n",
       "      <td>9.868609</td>\n",
       "      <td>2.506100</td>\n",
       "      <td>-5.837726</td>\n",
       "      <td>silverbush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.895515</td>\n",
       "      <td>-3.159792</td>\n",
       "      <td>2.894783</td>\n",
       "      <td>-3.287399</td>\n",
       "      <td>1.636786</td>\n",
       "      <td>2.641953</td>\n",
       "      <td>-2.551905</td>\n",
       "      <td>-1.621515</td>\n",
       "      <td>-3.864995</td>\n",
       "      <td>3.834533</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.033193</td>\n",
       "      <td>0.238001</td>\n",
       "      <td>2.521177</td>\n",
       "      <td>-1.292326</td>\n",
       "      <td>3.004183</td>\n",
       "      <td>2.188133</td>\n",
       "      <td>1.812453</td>\n",
       "      <td>1.697163</td>\n",
       "      <td>-2.271131</td>\n",
       "      <td>common dandelion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_0    feat_1    feat_2    feat_3     feat_4    feat_5    feat_6  \\\n",
       "0 -0.800802 -6.686755  2.291890 -6.562728   7.745037  6.728537 -2.491809   \n",
       "1 -1.062384 -9.090408  2.106473 -8.307278  10.665771  9.068426 -3.133069   \n",
       "2 -0.133140 -5.564013  7.093954 -6.700411   5.081787  4.433008 -3.458238   \n",
       "3 -1.015239 -8.601444  2.186274 -7.964367  10.071804  8.585188 -2.997392   \n",
       "4  0.895515 -3.159792  2.894783 -3.287399   1.636786  2.641953 -2.551905   \n",
       "\n",
       "     feat_7    feat_8     feat_9  ...    feat_95   feat_96   feat_97  \\\n",
       "0 -4.484881 -2.737143   7.932643  ...  -7.565012  5.332066  0.745956   \n",
       "1 -5.898288 -2.975612  10.400145  ... -10.275208  7.315140  0.826239   \n",
       "2 -2.864730 -3.854272   7.458284  ...  -3.598590  2.709342  1.422618   \n",
       "3 -5.624932 -2.950619   9.911002  ...  -9.716297  6.910458  0.792586   \n",
       "4 -1.621515 -3.864995   3.834533  ...  -2.033193  0.238001  2.521177   \n",
       "\n",
       "    feat_98   feat_99  feat_100   feat_101  feat_102  feat_103  \\\n",
       "0  2.969701  2.638199  7.016939   7.624356  2.285954 -4.529178   \n",
       "1  4.833378  2.779420  9.377540  10.458584  2.551416 -6.206422   \n",
       "2  0.412841  4.528669  3.052601   4.200697  3.536117 -2.623990   \n",
       "3  4.439338  2.776150  8.899710   9.868609  2.506100 -5.837726   \n",
       "4 -1.292326  3.004183  2.188133   1.812453  1.697163 -2.271131   \n",
       "\n",
       "              label  \n",
       "0          foxglove  \n",
       "1    passion flower  \n",
       "2      common tulip  \n",
       "3        silverbush  \n",
       "4  common dandelion  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris                        228\n",
      "wild rose                   216\n",
      "wild geranium               205\n",
      "common dandelion            164\n",
      "sunflower                   134\n",
      "                           ... \n",
      "prince of wales feathers      6\n",
      "moon orchid                   5\n",
      "alpine sea holly              5\n",
      "siam tulip                    5\n",
      "bolero deep blue              5\n",
      "Name: label, Length: 104, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = df.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tSNE_metrics = TSNE(n_components=2, random_state=0).fit_transform(predicted_metrics[:30])\n",
    "\n",
    "plt.scatter(tSNE_metrics[:, 0], tSNE_metrics[:, 1], c=labels[:30])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPK/Ca6rzwfR4hwf84DjDn5",
   "collapsed_sections": [],
   "mount_file_id": "1bA3m4MERyvaV_nRSD6GX3HLWa44FkmBR",
   "name": "flower classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "best-env",
   "language": "python",
   "name": "best-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
